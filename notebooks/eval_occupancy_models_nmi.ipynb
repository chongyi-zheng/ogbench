{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67ab8891",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: XDG_RUNTIME_DIR is invalid or not set in the environment.\n",
      "2025-08-04 22:34:00.827793: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-04 22:34:00.870633: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-04 22:34:00.870666: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-04 22:34:00.871984: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-04 22:34:00.878849: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-04 22:34:02.172780: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:py.warnings:/u/cz8792/.conda/envs/ogbench/lib/python3.10/site-packages/Cython/Distutils/old_build_ext.py:15: DeprecationWarning: dep_util is Deprecated. Use functions from setuptools instead.\n",
      "  from distutils.dep_util import newer, newer_group\n",
      "\n",
      "WARNING:py.warnings:/u/cz8792/.conda/envs/ogbench/lib/python3.10/site-packages/Cython/Distutils/old_build_ext.py:15: DeprecationWarning: dep_util is Deprecated. Use functions from setuptools instead.\n",
      "  from distutils.dep_util import newer, newer_group\n",
      "\n",
      "WARNING:py.warnings:<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "from absl import flags\n",
    "from ml_collections import config_flags\n",
    "from collections import defaultdict\n",
    "from tqdm import trange\n",
    "from PIL import Image, ImageEnhance\n",
    "import moviepy.editor as mpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "from agents import agents\n",
    "from utils.env_utils import make_env_and_datasets\n",
    "from utils.datasets import Dataset\n",
    "from utils.flax_utils import restore_agent\n",
    "from utils.evaluation import supply_rng, add_to, flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "069bbc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FLAGS = flags.FLAGS\n",
    "\n",
    "# flags.DEFINE_string('env_name', 'quadruped_jump', 'Environment (dataset) name.')\n",
    "# flags.DEFINE_string('env_name', 'scene-play-singletask-task1-v0', 'Environment (dataset) name.')\n",
    "flags.DEFINE_string('env_name', 'cube-single-play-singletask-task2-v0', 'Environment (dataset) name.')\n",
    "flags.DEFINE_integer('seed', 10, 'Random seed.')\n",
    "flags.DEFINE_string('obs_norm_type', 'normal', 'Type of observation normalization. (none, normal, bounded)')\n",
    "flags.DEFINE_float('p_aug', None, 'Probability of applying image augmentation.')\n",
    "flags.DEFINE_integer('num_aug', 1, 'Number of image augmentations.')\n",
    "flags.DEFINE_integer('inplace_aug', 1, 'Whether to replace the original image after applying augmentations.')\n",
    "flags.DEFINE_integer('frame_stack', None, 'Number of frames to stack.')\n",
    "config_flags.DEFINE_config_file('agent', '../impls/agents/sarsa_ifql_vib_gpi.py', lock_config=False)\n",
    "# config_flags.DEFINE_config_file('agent', '../impls/agents/fb_repr_fom.py', lock_config=False)\n",
    "\n",
    "if not FLAGS.is_parsed():\n",
    "    FLAGS(sys.argv, known_only=True)\n",
    "\n",
    "config = FLAGS.agent\n",
    "config['latent_dim'] = 512\n",
    "config['clip_flow_goals'] = True\n",
    "# config['transition_layer_norm'] = True\n",
    "config['value_layer_norm'] = True\n",
    "\n",
    "_, env, dataset, _ = make_env_and_datasets(\n",
    "    FLAGS.env_name, frame_stack=FLAGS.frame_stack, max_size=10_000_000, reward_free=True)\n",
    "\n",
    "# Initialize agent.\n",
    "random.seed(FLAGS.seed)\n",
    "np.random.seed(FLAGS.seed)\n",
    "tf.random.set_seed(FLAGS.seed)\n",
    "\n",
    "# Set up datasets.\n",
    "dataset = Dataset.create(**dataset)\n",
    "dataset.obs_norm_type = FLAGS.obs_norm_type\n",
    "dataset.p_aug = FLAGS.p_aug\n",
    "dataset.num_aug = FLAGS.num_aug\n",
    "dataset.inplace_aug = FLAGS.inplace_aug\n",
    "dataset.frame_stack = FLAGS.frame_stack\n",
    "dataset.return_next_actions = True\n",
    "dataset.normalize_observations()\n",
    "\n",
    "example_batch = dataset.sample(1)\n",
    "\n",
    "agent_class = agents[config['agent_name']]\n",
    "agent = agent_class.create(\n",
    "    FLAGS.seed,\n",
    "    example_batch['observations'],\n",
    "    example_batch['actions'],\n",
    "    config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "874c067f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored from /n/fs/rl-chongyiz/exp_logs/ogbench_logs/sarsa_ifql_vib_gpi_offline2offline/20250727_sarsa_ifql_vib_gpi_offline2offline_cube-single-play-singletask-task2-v0_obs_norm=normal_alpha=30.0_ft_size=500000_ft_steps=500000_eval_freq=10000_num_fg=16_actor_freq=4_expectile=0.95_actor_ln=False_kl_weight=0.05_latent_dim=512_value_ln=True/200/debug/sd200_s_24622607.0.20250727_230701/params_1500000.pkl\n"
     ]
    }
   ],
   "source": [
    "# InFOM\n",
    "# restore_path = '/n/fs/rl-chongyiz/exp_logs/ogbench_logs/sarsa_ifql_vib_gpi_offline2offline/20250504_sarsa_ifql_vib_gpi_offline2offline_quadruped_jump_obs_norm=normal_alpha=0.3_num_fg=16_actor_freq=4_expectile=0.9_critic_z_type=prior_vf_time_emb=False_transition_ln=True_kl_weight=0.005_latent_dim=128/300/debug/sd300_s_23747733.0.20250504_064407'\n",
    "# restore_path = '/n/fs/rl-chongyiz/exp_logs/ogbench_logs/sarsa_ifql_vib_gpi_offline2offline/20250509_sarsa_ifql_vib_gpi_offline2offline_scene-play-singletask-task1-v0_obs_norm=normal_alpha=300.0_num_fg=16_actor_freq=4_expectile=0.99_critic_z_type=prior_vf_time_emb=False_actor_ln=False_kl_weight=0.2_latent_dim=128_clip_fg=True/200/debug/sd200_s_2154372.0.20250509_015603'\n",
    "restore_path = '/n/fs/rl-chongyiz/exp_logs/ogbench_logs/sarsa_ifql_vib_gpi_offline2offline/20250727_sarsa_ifql_vib_gpi_offline2offline_cube-single-play-singletask-task2-v0_obs_norm=normal_alpha=30.0_ft_size=500000_ft_steps=500000_eval_freq=10000_num_fg=16_actor_freq=4_expectile=0.95_actor_ln=False_kl_weight=0.05_latent_dim=512_value_ln=True/200/debug/sd200_s_24622607.0.20250727_230701'\n",
    "# restore_path = '/n/fs/rl-chongyiz/exp_logs/ogbench_logs/sarsa_ifql_vib_gpi_offline2offline/20250727_sarsa_ifql_vib_gpi_offline2offline_cube-single-play-singletask-task2-v0_obs_norm=normal_alpha=30.0_ft_size=500000_ft_steps=500000_eval_freq=10000_num_fg=16_actor_freq=4_expectile=0.95_actor_ln=False_kl_weight=0.05_latent_dim=512_value_ln=True/300/debug/sd300_s_24622608.0.20250727_231001'\n",
    "# restore_path = '/n/fs/rl-chongyiz/exp_logs/ogbench_logs/sarsa_ifql_vib_gpi_offline2offline/20250727_sarsa_ifql_vib_gpi_offline2offline_cube-single-play-singletask-task2-v0_obs_norm=normal_alpha=30.0_ft_size=500000_ft_steps=500000_eval_freq=10000_num_fg=16_actor_freq=4_expectile=0.95_actor_ln=False_kl_weight=0.05_latent_dim=512_value_ln=True/400/debug/sd400_s_24620336.0.20250728_005443'\n",
    "# FOM\n",
    "# restore_path = '/n/fs/rl-chongyiz/exp_logs/ogbench_logs/fb_repr_fom_offline2offline/20250512_fb_repr_fom_offline2offline_quadruped_jump_obs_norm_type=normal_repr_alpha=10.0_alpha=0.3_num_fg=16_expectile=0.9_actor_freq=4_latent_dim=128_clip_fg=True/200/debug/sd200_s_2156137.0.20250512_132446'\n",
    "restore_epoch = 1_500_000\n",
    "\n",
    "agent_class = agents[config['agent_name']]\n",
    "agent = agent_class.create(\n",
    "    FLAGS.seed,\n",
    "    example_batch['observations'],\n",
    "    example_batch['actions'],\n",
    "    config,\n",
    ")\n",
    "agent = restore_agent(agent, restore_path, restore_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592d2953",
   "metadata": {},
   "source": [
    "##### InFOM quadruped_jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9375f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 999, 512)\n",
      "NMI: 0.003678\n",
      "AMI: 0.003350\n"
     ]
    }
   ],
   "source": [
    "rng = jax.random.PRNGKey(FLAGS.seed)\n",
    "(terminal_locs,) = np.nonzero(dataset['terminals'] > 0)\n",
    "initial_locs = np.concatenate([[0], terminal_locs[:-1] + 1])\n",
    "\n",
    "num_trajs = 40\n",
    "num_flow_futre_states = 400\n",
    "\n",
    "idxs = np.array([0 * 1000, 100 * 1000, # stand\n",
    "                 300 * 1000, 400 * 1000,  # two leg balances\n",
    "                 600 * 1000, 700 * 1000,  # flip and stand\n",
    "                 ])\n",
    "initial_idxs = initial_locs[np.searchsorted(initial_locs, idxs, side='right') - 1]\n",
    "terminal_idxs = terminal_locs[np.searchsorted(terminal_locs, idxs)]\n",
    "\n",
    "trajs = defaultdict(list)\n",
    "for init_idx, term_idx in zip(initial_idxs, terminal_idxs):\n",
    "    trajs['observations'].append(dataset['observations'][init_idx:term_idx + 1])\n",
    "    trajs['actions'].append(dataset['actions'][init_idx:term_idx + 1])\n",
    "\n",
    "trajs['observations'] = np.asarray(trajs['observations'])\n",
    "trajs['actions'] = np.asarray(trajs['actions'])\n",
    "\n",
    "initial_observations = jnp.asarray(trajs['observations'][:, 0])\n",
    "initial_actions = jnp.asarray(trajs['actions'][:, 0])\n",
    "initial_next_observations = jnp.asarray(trajs['observations'][:, 1])\n",
    "initial_next_actions = jnp.asarray(trajs['actions'][:, 1])\n",
    "# next_observations = jnp.asarray(trajs['observations'][:, 1:])\n",
    "# next_actions = jnp.asarray(trajs['actions'][:, 1:])\n",
    "labels = np.zeros((*trajs['observations'][:, 1:].shape[:-1], ), dtype=np.int32)\n",
    "labels[0:2] = 0\n",
    "labels[2:4] = 1\n",
    "labels[4:6] = 2\n",
    "\n",
    "# predict z\n",
    "latent_dist = agent.network.select('transition_encoder')(next_observations, next_actions)\n",
    "latents = latent_dist.mode()\n",
    "latents = np.asarray(latents)\n",
    "\n",
    "print(latents.shape)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_mutual_info_score\n",
    "\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "preds = kmeans.fit_predict(latents.reshape(-1, 512))\n",
    "\n",
    "labels = labels.reshape(-1)\n",
    "nmi = normalized_mutual_info_score(labels, preds, average_method=\"arithmetic\")\n",
    "ami = adjusted_mutual_info_score(labels, preds, average_method=\"arithmetic\")\n",
    "\n",
    "print(\"NMI: {:.6f}\".format(nmi))\n",
    "print(\"AMI: {:.6f}\".format(ami))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "331b7df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 400, 28)\n",
      "NMI: 0.304764\n",
      "AMI: 0.304236\n"
     ]
    }
   ],
   "source": [
    "rng = jax.random.PRNGKey(FLAGS.seed)\n",
    "(terminal_locs,) = np.nonzero(dataset['terminals'] > 0)\n",
    "initial_locs = np.concatenate([[0], terminal_locs[:-1] + 1])\n",
    "\n",
    "num_trajs = 40\n",
    "num_flow_futre_states = 400\n",
    "\n",
    "idxs = np.array([0 * 1000, 100 * 1000, # stand\n",
    "                 300 * 1000, 400 * 1000,  # two leg balances\n",
    "                 600 * 1000, 700 * 1000,  # flip and stand\n",
    "                 ])\n",
    "initial_idxs = initial_locs[np.searchsorted(initial_locs, idxs, side='right') - 1]\n",
    "terminal_idxs = terminal_locs[np.searchsorted(terminal_locs, idxs)]\n",
    "\n",
    "trajs = defaultdict(list)\n",
    "for init_idx, term_idx in zip(initial_idxs, terminal_idxs):\n",
    "    trajs['observations'].append(dataset['observations'][init_idx:term_idx + 1])\n",
    "    trajs['actions'].append(dataset['actions'][init_idx:term_idx + 1])\n",
    "\n",
    "trajs['observations'] = np.asarray(trajs['observations'])\n",
    "trajs['actions'] = np.asarray(trajs['actions'])\n",
    "\n",
    "initial_observations = jnp.asarray(trajs['observations'][:, 0])\n",
    "initial_actions = jnp.asarray(trajs['actions'][:, 0])\n",
    "initial_next_observations = jnp.asarray(trajs['observations'][:, 1])\n",
    "initial_next_actions = jnp.asarray(trajs['actions'][:, 1])\n",
    "# next_observations = jnp.asarray(trajs['observations'][:, 1:])\n",
    "# next_actions = jnp.asarray(trajs['actions'][:, 1:])\n",
    "\n",
    "# predict z\n",
    "latent_dist = agent.network.select('transition_encoder')(initial_next_observations, initial_next_actions)\n",
    "latents = latent_dist.mode()\n",
    "\n",
    "# sample future states\n",
    "rng, noise_rng = jax.random.split(rng)\n",
    "noises = jax.random.normal(\n",
    "    noise_rng,\n",
    "    shape=(num_flow_futre_states, *initial_observations.shape),\n",
    "    dtype=initial_observations.dtype\n",
    ")\n",
    "flow_future_states = agent.compute_fwd_flow_goals(\n",
    "    noises,\n",
    "    jnp.broadcast_to(\n",
    "        initial_observations[None],\n",
    "        (num_flow_futre_states, *initial_observations.shape)\n",
    "    ),\n",
    "    jnp.broadcast_to(\n",
    "        initial_actions[None],\n",
    "        (num_flow_futre_states, *initial_actions.shape)\n",
    "    ),\n",
    "    jnp.broadcast_to(\n",
    "        latents[None],\n",
    "        (num_flow_futre_states, *latents.shape)\n",
    "    ),\n",
    "    observation_min=example_batch['observation_min'],\n",
    "    observation_max=example_batch['observation_max'],\n",
    ")\n",
    "flow_future_states = flow_future_states.transpose([1, 0, 2])\n",
    "\n",
    "labels = np.zeros((*flow_future_states.shape[:-1], ), dtype=np.int32)\n",
    "labels[0:2] = 0\n",
    "labels[2:4] = 1\n",
    "labels[4:6] = 2\n",
    "\n",
    "print(flow_future_states.shape)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_mutual_info_score\n",
    "\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "preds = kmeans.fit_predict(flow_future_states.reshape(-1, 28))\n",
    "\n",
    "labels = labels.reshape(-1)\n",
    "nmi = normalized_mutual_info_score(labels, preds, average_method=\"arithmetic\")\n",
    "ami = adjusted_mutual_info_score(labels, preds, average_method=\"arithmetic\")\n",
    "\n",
    "print(\"NMI: {:.6f}\".format(nmi))\n",
    "print(\"AMI: {:.6f}\".format(ami))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459c7c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30353787499999996\n",
      "0.0021967269651404025\n"
     ]
    }
   ],
   "source": [
    "a = np.array([0.303244, 0.304764, 0.304764, 0.302425, 0.303121, 0.306351, 0.305000, 0.298634])\n",
    "print(np.mean(a))\n",
    "print(np.std(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80475237",
   "metadata": {},
   "source": [
    "##### InFOM scene-play-singletask-task1-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae75eda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(FLAGS.seed)\n",
    "(terminal_locs,) = np.nonzero(dataset['terminals'] > 0)\n",
    "initial_locs = np.concatenate([[0], terminal_locs[:-1] + 1])\n",
    "\n",
    "num_trajs = 40\n",
    "num_flow_futre_states = 400\n",
    "\n",
    "idxs = np.random.randint(dataset.size, size=num_trajs)\n",
    "initial_idxs = initial_locs[np.searchsorted(initial_locs, idxs, side='right') - 1]\n",
    "terminal_idxs = terminal_locs[np.searchsorted(terminal_locs, idxs)]\n",
    "\n",
    "trajs = defaultdict(list)\n",
    "for init_idx, term_idx in zip(initial_idxs, terminal_idxs):\n",
    "    trajs['observations'].append(dataset['observations'][init_idx:term_idx + 1])\n",
    "    trajs['actions'].append(dataset['actions'][init_idx:term_idx + 1])\n",
    "\n",
    "trajs['observations'] = np.asarray(trajs['observations'])\n",
    "trajs['actions'] = np.asarray(trajs['actions'])\n",
    "\n",
    "initial_observations = jnp.asarray(trajs['observations'][:, 0])\n",
    "initial_actions = jnp.asarray(trajs['actions'][:, 0])\n",
    "initial_next_observations = jnp.asarray(trajs['observations'][:, 1])\n",
    "initial_next_actions = jnp.asarray(trajs['actions'][:, 1])\n",
    "\n",
    "# predict z\n",
    "latent_dist = agent.network.select('transition_encoder')(initial_next_observations, initial_next_actions)\n",
    "latents = latent_dist.mode()\n",
    "\n",
    "# sample future states\n",
    "rng, noise_rng = jax.random.split(rng)\n",
    "noises = jax.random.normal(\n",
    "    noise_rng,\n",
    "    shape=(num_flow_futre_states, *initial_observations.shape),\n",
    "    dtype=initial_observations.dtype\n",
    ")\n",
    "flow_future_states = agent.compute_fwd_flow_goals(\n",
    "    noises,\n",
    "    jnp.broadcast_to(\n",
    "        initial_observations[None],\n",
    "        (num_flow_futre_states, *initial_observations.shape)\n",
    "    ),\n",
    "    jnp.broadcast_to(\n",
    "        initial_actions[None],\n",
    "        (num_flow_futre_states, *initial_actions.shape)\n",
    "    ),\n",
    "    jnp.broadcast_to(\n",
    "        latents[None],\n",
    "        (num_flow_futre_states, *latents.shape)\n",
    "    ),\n",
    "    observation_min=example_batch['observation_min'],\n",
    "    observation_max=example_batch['observation_max'],\n",
    ")\n",
    "flow_future_states = flow_future_states.transpose([1, 0, 2])\n",
    "\n",
    "print(flow_future_states.shape)\n",
    "print(((flow_future_states[:, :, None] - trajs['observations'][:, None]) ** 2).shape)\n",
    "\n",
    "pairwise_mse = jnp.mean((flow_future_states[:, :, None] - trajs['observations'][:, None]) ** 2)\n",
    "print(pairwise_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2974722f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ogbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
