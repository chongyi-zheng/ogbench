{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7788e096",
   "metadata": {},
   "source": [
    "import sys\n",
    "\n",
    "from absl import flags\n",
    "from ml_collections import config_flags\n",
    "from collections import defaultdict\n",
    "import tqdm\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "import random\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "from agents import agents\n",
    "from utils.env_utils import make_env_and_datasets\n",
    "from utils.flax_utils import restore_agent\n",
    "from utils.evaluation import supply_rng, add_to, flatten\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e843796",
   "metadata": {},
   "source": [
    "FLAGS = flags.FLAGS\n",
    "\n",
    "# flags.DEFINE_string('env_name', 'antmaze-medium-stitch-v0', 'Environment (dataset) name.')\n",
    "# flags.DEFINE_integer('seed', 0, 'Random seed.')\n",
    "config_flags.DEFINE_config_file('agent', '../impls/agents/qrl.py', lock_config=False)\n",
    "\n",
    "env_name = 'antmaze-medium-stitch-v0'\n",
    "seed = 1\n",
    "\n",
    "if not FLAGS.is_parsed():\n",
    "    FLAGS(sys.argv, known_only=True)\n",
    "\n",
    "config = FLAGS.agent\n",
    "env, train_dataset, val_dataset = make_env_and_datasets(env_name, frame_stack=config['frame_stack'])\n",
    "\n",
    "# Initialize agent.\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "example_batch = train_dataset.sample(1)\n",
    "\n",
    "agent_class = agents[config['agent_name']]\n",
    "agent = agent_class.create(\n",
    "    seed,\n",
    "    example_batch['observations'],\n",
    "    example_batch['actions'],\n",
    "    config,\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eb731f1",
   "metadata": {},
   "source": [
    "# restore_dir = \"/n/fs/rl-chongyiz/exp_logs/hdualrl_logs/psiql/20250618_psiql_antmaze-large-navigate-v0_expectile=0.7_alpha=3.0_discount=0.99/1/debug/sd001_s_24251254.0.20250618_134110\"\n",
    "restore_dir = \"/n/fs/rl-chongyiz/exp_logs/ogbench_logs/qrl/20250615_qrl_antmaze-medium-stitch-v0_alpha=0.003_discount=0.99_squared_transition_loss=False/1/debug/sd001_s_24218514.0.20250615_150752\"\n",
    "# restore_dir = \"/n/fs/rl-chongyiz/exp_logs/ogbench_logs/qrl/20250615_qrl_antmaze-medium-stitch-v0_alpha=0.003_discount=0.99_squared_transition_loss=True/3/debug/sd003_s_24218513.0.20250615_150751\"\n",
    "restore_epoch = 1_000_000\n",
    "\n",
    "agent = restore_agent(agent, restore_dir, restore_epoch)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7405b2a3",
   "metadata": {},
   "source": [
    "@jax.jit\n",
    "def sample_actions(\n",
    "    observations,\n",
    "    agent=agent,\n",
    "    goals=None,\n",
    "    seed=None,\n",
    "    temperature=1.0,\n",
    "):\n",
    "    \"\"\"Sample actions from the actor.\n",
    "\n",
    "    It first queries the high-level actor to obtain subgoal representations, and then queries the low-level actor\n",
    "    to obtain raw actions.\n",
    "    \"\"\"\n",
    "    # seed, waypoint_seed, action_seed = jax.random.split(seed, 3)\n",
    "\n",
    "    # TODO: posterior sampling\n",
    "    # candidates = jnp.concatenate([\n",
    "    #     jnp.expand_dims(observations, 0),\n",
    "    #     candidates,\n",
    "    #     jnp.expand_dims(goals, 0)\n",
    "    # ], axis=0)\n",
    "\n",
    "    # n_observations = jnp.repeat(jnp.expand_dims(observations, 0), candidates.shape[0], axis=0)\n",
    "    # n_goals = jnp.repeat(jnp.expand_dims(observations, 0), candidates.shape[0], axis=0)\n",
    "\n",
    "    # v_sw1, v_sw2 = agent.network.select('value')(n_observations, candidates)\n",
    "    # v_sw = (v_sw1 + v_sw2) / 2\n",
    "\n",
    "    # v_wg1, v_wg2 = agent.network.select('value')(candidates, n_goals)\n",
    "    # v_wg = (v_wg1 + v_wg2) / 2\n",
    "\n",
    "    # v_sg1, v_sg2 = agent.network.select('value')(n_observations, n_goals)\n",
    "    # v_sg = (v_sg1 + v_sg2) / 2\n",
    "\n",
    "    # logits = v_sw + v_wg - v_sg\n",
    "    # waypoint_idx = jax.random.categorical(waypoint_seed, logits)\n",
    "    # waypoint = candidates[waypoint_idx]\n",
    "\n",
    "    dist = agent.network.select('actor')(observations, goals, temperature=temperature)\n",
    "    actions = dist.sample(seed=seed)\n",
    "    actions = jnp.clip(actions, -1, 1)\n",
    "\n",
    "    return actions\n",
    "\n",
    "num_eval_episodes = 10\n",
    "num_video_episodes = 1\n",
    "video_frame_skip = 3\n",
    "eval_temperature = 0.0\n",
    "task_infos = env.unwrapped.task_infos if hasattr(env.unwrapped, 'task_infos') else env.task_infos\n",
    "num_tasks = len(task_infos)\n",
    "\n",
    "task_stats = defaultdict()\n",
    "renders = []\n",
    "for task_id in tqdm.trange(1, num_tasks + 1):\n",
    "    actor_fn = supply_rng(sample_actions, rng=jax.random.PRNGKey(np.random.randint(0, 2**32)))\n",
    "    trajs = []\n",
    "    stats = defaultdict(list)\n",
    "\n",
    "    cur_renders = []\n",
    "    for i in tqdm.trange(num_eval_episodes + num_video_episodes):\n",
    "        traj = defaultdict(list)\n",
    "        should_render = i >= num_eval_episodes\n",
    "\n",
    "        observation, info = env.reset(options=dict(task_id=task_id))\n",
    "        goal = info.get('goal')\n",
    "        goal_frame = info.get('goal_rendered')\n",
    "        done = False\n",
    "        step = 0\n",
    "        render = []\n",
    "        while not done:\n",
    "            action = actor_fn(observations=observation, goals=goal, temperature=eval_temperature)\n",
    "            action = np.array(action)\n",
    "            action = np.clip(action, -1, 1)\n",
    "\n",
    "            next_observation, reward, terminated, truncated, info = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            step += 1\n",
    "            \n",
    "            if should_render and (step % video_frame_skip == 0 or done):\n",
    "                frame = env.render().copy()\n",
    "                if goal_frame is not None:\n",
    "                    render.append(np.concatenate([goal_frame, frame], axis=0))\n",
    "                else:\n",
    "                    render.append(frame)\n",
    "\n",
    "            transition = dict(\n",
    "                observation=observation,\n",
    "                next_observation=next_observation,\n",
    "                action=action,\n",
    "                reward=reward,\n",
    "                done=done,\n",
    "                info=info,\n",
    "            )\n",
    "            add_to(traj, transition)\n",
    "            observation = next_observation\n",
    "        if i < num_eval_episodes:\n",
    "            add_to(stats, flatten(info))\n",
    "            trajs.append(traj)\n",
    "        else:\n",
    "            cur_renders.append(np.array(render))\n",
    "\n",
    "    for k, v in stats.items():\n",
    "        stats[k] = np.mean(v)\n",
    "\n",
    "    for k, v in stats.items():\n",
    "        task_stats['task{}/'.format(task_id) + k] = v\n",
    "    \n",
    "    renders.extend(cur_renders)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ed32dc3",
   "metadata": {},
   "source": [
    "for task in range(1, num_tasks + 1):\n",
    "    task_success = task_stats[f'task{task}/success']\n",
    "    \n",
    "    print(f\"task{task}/success: {task_success}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8d59d36",
   "metadata": {},
   "source": [
    "def get_video(renders=None, n_cols=None, fps=15):\n",
    "    \"\"\"Return a Weights & Biases video.\n",
    "\n",
    "    It takes a list of videos and reshapes them into a single video with the specified number of columns.\n",
    "\n",
    "    Args:\n",
    "        renders: List of videos. Each video should be a numpy array of shape (t, h, w, c).\n",
    "        n_cols: Number of columns for the reshaped video. If None, it is set to the square root of the number of videos.\n",
    "    \"\"\"\n",
    "    # Pad videos to the same length.\n",
    "    max_length = max([len(render) for render in renders])\n",
    "    for i, render in enumerate(renders):\n",
    "        assert render.dtype == np.uint8\n",
    "\n",
    "        # Decrease brightness of the padded frames.\n",
    "        final_frame = render[-1]\n",
    "        final_image = Image.fromarray(final_frame)\n",
    "        enhancer = ImageEnhance.Brightness(final_image)\n",
    "        final_image = enhancer.enhance(0.5)\n",
    "        final_frame = np.array(final_image)\n",
    "\n",
    "        pad = np.repeat(final_frame[np.newaxis, ...], max_length - len(render), axis=0)\n",
    "        renders[i] = np.concatenate([render, pad], axis=0)\n",
    "\n",
    "        # Add borders.\n",
    "        renders[i] = np.pad(renders[i], ((0, 0), (1, 1), (1, 1), (0, 0)), mode='constant', constant_values=0)\n",
    "    renders = np.array(renders)  # (n, t, h, w, c)\n",
    "\n",
    "    return renders\n",
    "\n",
    "renders = get_video(renders)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f175c52",
   "metadata": {},
   "source": [
    "import moviepy.editor as mpy\n",
    "\n",
    "clip = mpy.ImageSequenceClip(list(renders[1]), fps=30)\n",
    "\n",
    "clips = [mpy.ImageSequenceClip(list(frames), fps=30) for frames in renders]\n",
    "clip_row = mpy.clips_array([clips])\n",
    "\n",
    "clip_row.ipython_display(fps=30, loop=True, autoplay=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f89a76",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ogbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
