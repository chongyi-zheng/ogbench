{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f74e1819",
   "metadata": {},
   "source": [
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63138460",
   "metadata": {},
   "source": [
    "def find_csv_files(log_dir, algos, filename) -> list[Path]:\n",
    "    # Matches â€¦/<SEED>/debug/**/finetuning_eval.csv  (depth under debug doesn't matter)\n",
    "    \n",
    "    csv_files = dict()\n",
    "    for algo, env_name, exp_log_dir in algos:\n",
    "        pattern = os.path.join(log_dir, algo, exp_log_dir, \"*\", \"debug\", \"**\", filename)\n",
    "        files = [p for p in glob.glob(pattern, recursive=True)]\n",
    "        if env_name not in csv_files:\n",
    "            csv_files[env_name] = {algo: files}\n",
    "        else:\n",
    "            csv_files[env_name][algo] = files \n",
    "    return csv_files\n",
    "\n",
    "\n",
    "log_dir = \"/n/fs/rl-chongyiz/exp_logs/ogbench_logs\"\n",
    "algos = [\n",
    "    # (\"sarsa_ifql_vib_gpi_offline2offline\", \"cheetah_run\", \"20250504_sarsa_ifql_vib_gpi_offline2offline_cheetah_run_obs_norm=normal_alpha=0.3_num_fg=16_actor_freq=4_expectile=0.9_critic_z_type=prior_vf_time_emb=False_transition_ln=True_kl_weight=0.15_latent_dim=128\"),\n",
    "    # (\"fb_repr_fom_offline2offline\", \"cheetah_run\", \"20250507_fb_repr_fom_offline2offline_cheetah_run_obs_norm_type=normal_repr_alpha=10.0_alpha=0.3_num_fg=16_expectile=0.9_actor_freq=4_clip_fg=True\"),\n",
    "\n",
    "    # (\"sarsa_ifql_vib_gpi_offline2offline\", \"quadruped_jump\", \"20250504_sarsa_ifql_vib_gpi_offline2offline_quadruped_jump_obs_norm=normal_alpha=0.3_num_fg=16_actor_freq=4_expectile=0.9_critic_z_type=prior_vf_time_emb=False_transition_ln=True_kl_weight=0.005_latent_dim=128\"),\n",
    "    # (\"fb_repr_fom_offline2offline\", \"quadruped_jump\", \"20250507_fb_repr_fom_offline2offline_quadruped_jump_obs_norm_type=normal_repr_alpha=1.0_alpha=0.3_num_fg=16_expectile=0.9_actor_freq=4_clip_fg=True\"),\n",
    "\n",
    "    # (\"sarsa_ifql_vib_gpi_offline2offline\", \"walker_walk\", \"20250504_sarsa_ifql_vib_gpi_offline2offline_walker_walk_obs_norm=normal_alpha=0.3_num_fg=16_actor_freq=4_expectile=0.9_critic_z_type=prior_vf_time_emb=False_transition_ln=True_kl_weight=0.05_latent_dim=128\"),\n",
    "    # (\"fb_repr_fom_offline2offline\", \"walker_walk\", \"20250507_fb_repr_fom_offline2offline_walker_walk_obs_norm_type=normal_repr_alpha=1.0_alpha=0.3_num_fg=16_expectile=0.9_actor_freq=4_clip_fg=True\"),\n",
    "\n",
    "    (\"sarsa_ifql_vib_gpi_offline2offline\", \"walker_flip\", \"20250508_sarsa_ifql_vib_gpi_offline2offline_walker_flip_obs_norm=normal_alpha=0.3_num_fg=16_actor_freq=4_expectile=0.9_critic_z_type=prior_vf_time_emb=False_actor_ln=False_kl_weight=0.05_latent_dim=64_clip_fg=True\"),\n",
    "    (\"fb_repr_fom_offline2offline\", \"walker_flip\", \"20250512_fb_repr_fom_offline2offline_walker_flip_obs_norm_type=normal_repr_alpha=1.0_alpha=0.3_num_fg=16_expectile=0.9_actor_freq=4_latent_dim=64_clip_fg=True\"),\n",
    "    (\"hilp_fom_offline2offline\", \"walker_flip\", \"20250512_hilp_fom_offline2offline_walker_flip_obs_norm_type=normal_alpha=0.3_num_fg=16_expectile=0.9_actor_freq=4_latent_dim=64_clip_fg=True\"),\n",
    "    \n",
    "    (\"sarsa_ifql_vib_gpi_offline2offline\", \"quadruped_jump\", \"20250504_sarsa_ifql_vib_gpi_offline2offline_quadruped_jump_obs_norm=normal_alpha=0.3_num_fg=16_actor_freq=4_expectile=0.9_critic_z_type=prior_vf_time_emb=False_transition_ln=True_kl_weight=0.005_latent_dim=128\"),\n",
    "    (\"fb_repr_fom_offline2offline\", \"quadruped_jump\", \"20250512_fb_repr_fom_offline2offline_quadruped_jump_obs_norm_type=normal_repr_alpha=10.0_alpha=0.3_num_fg=16_expectile=0.9_actor_freq=4_latent_dim=128_clip_fg=True\"),\n",
    "    (\"hilp_fom_offline2offline\", \"quadruped_jump\", \"20250512_hilp_fom_offline2offline_quadruped_jump_obs_norm_type=normal_alpha=0.3_num_fg=16_expectile=0.9_actor_freq=4_latent_dim=128_clip_fg=True\"),\n",
    "\n",
    "    (\"sarsa_ifql_vib_gpi_offline2offline\", \"cube-double-play-singletask-task1-v0\", \"20250508_sarsa_ifql_vib_gpi_offline2offline_cube-double-play-singletask-task1-v0_obs_norm=normal_alpha=30.0_num_fg=16_actor_freq=4_expectile=0.9_critic_z_type=prior_vf_time_emb=False_transition_ln=True_kl_weight=0.025_latent_dim=128_clip_fg=True\"),\n",
    "    (\"fb_repr_fom_offline2offline\", \"cube-double-play-singletask-task1-v0\", \"20250512_fb_repr_fom_offline2offline_cube-double-play-singletask-task1-v0_obs_norm_type=normal_repr_alpha=100.0_alpha=30.0_num_fg=16_expectile=0.9_actor_freq=4_latent_dim=128_clip_fg=True\"),\n",
    "    (\"hilp_fom_offline2offline\", \"cube-double-play-singletask-task1-v0\", \"20250512_hilp_fom_offline2offline_cube-double-play-singletask-task1-v0_obs_norm_type=normal_alpha=30.0_num_fg=16_expectile=0.9_actor_freq=4_latent_dim=128_clip_fg=True\"),\n",
    "    \n",
    "    (\"sarsa_ifql_vib_gpi_offline2offline\", \"scene-play-singletask-task1-v0\", \"20250509_sarsa_ifql_vib_gpi_offline2offline_scene-play-singletask-task1-v0_obs_norm=normal_alpha=300.0_num_fg=16_actor_freq=4_expectile=0.99_critic_z_type=prior_vf_time_emb=False_actor_ln=False_kl_weight=0.2_latent_dim=128_clip_fg=True\"),\n",
    "    (\"fb_repr_fom_offline2offline\", \"scene-play-singletask-task1-v0\", \"20250512_fb_repr_fom_offline2offline_scene-play-singletask-task1-v0_obs_norm_type=normal_repr_alpha=10.0_alpha=300.0_num_fg=16_expectile=0.99_actor_freq=4_latent_dim=128_clip_fg=True\"),\n",
    "    (\"hilp_fom_offline2offline\", \"scene-play-singletask-task1-v0\", \"20250512_hilp_fom_offline2offline_scene-play-singletask-task1-v0_obs_norm_type=normal_alpha=300.0_num_fg=16_expectile=0.99_actor_freq=4_latent_dim=128_clip_fg=True\"),\n",
    "]\n",
    "\n",
    "env_name_maps = {\n",
    "    'cheetah_run': 'cheetah run',\n",
    "    'quadruped_jump': 'quadruped jump',\n",
    "    'walker_walk': 'walker walk',\n",
    "    'walker_flip': 'walker flip',\n",
    "    'cube-double-play-singletask-task1-v0': 'cube double task 1',\n",
    "    'scene-play-singletask-task1-v0': 'scene task 1',\n",
    "}\n",
    "algo_name_maps = {\n",
    "    'sarsa_ifql_vib_gpi_offline2offline': 'InFOM (Ours)',\n",
    "    'fb_repr_fom_offline2offline': 'FB + FOM',\n",
    "    'hilp_fom_offline2offline': 'HILP + FOM',\n",
    "}\n",
    "\n",
    "\n",
    "csv_files = find_csv_files(log_dir, algos, filename=\"finetuning_eval.csv\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb983e22",
   "metadata": {},
   "source": [
    "def load_data(csv_path, stat_name, step_name) -> np.ndarray:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if stat_name not in df.columns:\n",
    "        raise KeyError(f\"{csv_path} doesn't contain {stat_name}\")\n",
    "    x = df[step_name].values\n",
    "    y = df[stat_name].values\n",
    "    return dict(x=x, y=y)\n",
    "\n",
    "\n",
    "algo_data = defaultdict(dict)\n",
    "for env_name, env_csv_files in csv_files.items():\n",
    "    for algo, csv_files in env_csv_files.items():\n",
    "        seed_data = []\n",
    "        for csv_file in csv_files:\n",
    "            if 'singletask' in csv_file:\n",
    "                data = load_data(csv_file, \"evaluation/episode.success\", \"step\")\n",
    "            else:\n",
    "                data = load_data(csv_file, \"evaluation/episode.return\", \"step\")\n",
    "            if len(seed_data) == 0:\n",
    "                seed_data.append(data[\"x\"])\n",
    "            else:\n",
    "                assert np.all(data[\"x\"] == seed_data[0])\n",
    "            seed_data.append(data[\"y\"])\n",
    "\n",
    "        seed_data = np.asarray(seed_data)\n",
    "        # steps = seed_data[0]\n",
    "        # data = seed_data[1:]\n",
    "        \n",
    "        algo_data[env_name_maps[env_name]][algo_name_maps[algo]] = seed_data\n",
    "        if len(seed_data) == 1:\n",
    "            print(\"Warning: only one random seed!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7d1adcc",
   "metadata": {},
   "source": [
    "print(algo_data['walker flip']['InFOM (Ours)'][0].shape)\n",
    "print(algo_data['walker flip']['InFOM (Ours)'][1:].shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06132ac",
   "metadata": {},
   "source": [
    "# fig, axes = plt.subplots(1, 4, figsize=(16, 3.2), gridspec_kw=dict(wspace=0.16, hspace=0.5))\n",
    "fig, axes = plt.subplots(1, 5, figsize=(13, 3.2), gridspec_kw={'width_ratios': [0.7, 0.7, 0.001, 0.7, 0.7]})\n",
    "fig.subplots_adjust(wspace=0.01)\n",
    "# fig.tight_layout(rect=(-0.1, 0.2, 1.015, 1.04))  # rect = (left, bottom, right, top), default: (0, 0, 1, 1)\n",
    "fig.tight_layout(rect=(0.01, 0.16, 1.02, 0.98))  # rect = (left, bottom, right, top), default: (0, 0, 1, 1)\n",
    "\n",
    "axes[2].axis('off')\n",
    "axes = [axes[0], axes[1], axes[3], axes[4]]\n",
    "\n",
    "for (env_name, env_data), ax in zip(algo_data.items(), axes):\n",
    "    for algo, data in env_data.items():\n",
    "        x = data[0] - 1e6\n",
    "        y = data[1:]\n",
    "        y = gaussian_filter1d(y, 0.75)\n",
    "        y_mean = np.mean(y, axis=0)\n",
    "        y_std = np.std(y, axis=0, ddof=1)\n",
    "        \n",
    "        l, = ax.plot(x, y_mean, label=algo, zorder=3)\n",
    "        ax.fill_between(x, y_mean - y_std, y_mean + y_std, alpha=0.3, lw=0, color=l.get_color(), zorder=3)\n",
    "\n",
    "    if ax == axes[0]:\n",
    "        ax.set_ylabel('return', fontsize=14)\n",
    "        ax.set_xlim([-1.25e4, 5e5 + 1.25e4])\n",
    "        ax.set_ylim([-10, 500 + 10])\n",
    "        ax.set_yticks([0, 200, 400])\n",
    "        ax.yaxis.set_minor_locator(MultipleLocator(100))\n",
    "        \n",
    "        ax.legend(bbox_to_anchor=(1.25, -0.22),\n",
    "            loc=\"upper left\", labelspacing=1, columnspacing=1.8075, fancybox=False,\n",
    "            shadow=False, fontsize=12.5, borderpad=0.5, handlelength=1.7, ncol=3)\n",
    "    if ax == axes[1]:\n",
    "        ax.set_xlim([-1.25e4, 5e5 + 1.25e4])\n",
    "        ax.set_ylim([-15, 800 + 15])\n",
    "        ax.set_yticks([0, 400, 800])\n",
    "        ax.yaxis.set_minor_locator(MultipleLocator(100))\n",
    "    if ax == axes[2]:\n",
    "        ax.set_ylabel('success rate', fontsize=14)\n",
    "        ax.set_xlim([-1.25e4, 5e5 + 1.25e4])\n",
    "        ax.set_ylim([-0.03, 0.5 + 0.03])\n",
    "        ax.set_yticks([0.0, 0.2, 0.4])\n",
    "        ax.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    if ax == axes[3]:\n",
    "        ax.set_xlim([-1.25e4, 5e5 + 1.25e4])\n",
    "        ax.set_ylim([-0.03, 1.0 + 0.03])\n",
    "        ax.set_yticks([0.0, 0.5, 1.0])\n",
    "        ax.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    \n",
    "    ax.set_title(env_name, fontsize=14)\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(1e5))\n",
    "    ax.set_xlabel('fine-tuning steps', fontsize=12)\n",
    "    ax.ticklabel_format(axis='x', style='sci', scilimits=(0, 0))  \n",
    "    \n",
    "    ax.grid(zorder=3)     \n",
    "\n",
    "# [left, bottom, width, height]\n",
    "# axes[1].set_position([0.1, 0.5, 0.4, 0.4])  # Adjust the position of this subplot\n",
    "\n",
    "# fig.tight_layout(rect=(-0.1, 0.2, 1.015, 1.04))  # rect = (left, bottom, right, top), default: (0, 0, 1, 1)\n",
    "filepath = \"/u/cz8792/research/ogbench/plot_scripts/figures/intention_encoding_ablation_lc.pdf\"\n",
    "# fig.savefig(filepath, dpi=150, bbox_inches=\"tight\")\n",
    "fig.savefig(filepath, dpi=300)\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d1fd89b",
   "metadata": {},
   "source": [
    "for env_name, env_data in algo_data.items():\n",
    "    for algo, data in env_data.items():\n",
    "        # x = data[0] - 1e6\n",
    "        y = data[1:, -3:].mean(axis=-1)\n",
    "        y_mean = np.mean(y, axis=0)\n",
    "        y_std = np.std(y, axis=0, ddof=1)\n",
    "        \n",
    "        print(f\"env = {env_name}, {algo}: mean = {y_mean:.4f}, std = {y_std:.4f}\")\n",
    "\n",
    "\n",
    "tasks = ['walker flip', 'quadruped jump', 'cube double task 1', 'scene task 1']\n",
    "\n",
    "\n",
    "\n",
    "infom_mean = np.array([367.6713, 626.0349, 0.2627, 0.9783])\n",
    "infom_std = np.array([21.1020, 6.8158, 0.0888, 0.0100])\n",
    "fb_fom_mean = np.array([253.8106, 647.4752, 0.0333, 0.5900])\n",
    "fb_fom_std = np.array([7.1819, 12.0109, 0.0377, 0.0519])\n",
    "hilp_fom_mean = np.array([278.0506, 402.4222, 0.0000, 0.3556])\n",
    "hilp_fom_std = np.array([4.5412, 88.0037, 0.0000, 0.0990])\n",
    "\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(8, 3.2), gridspec_kw=dict(wspace=0.28, hspace=0.05))\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 3.2))\n",
    "\n",
    "x = np.arange(2)\n",
    "width = 0.05\n",
    "\n",
    "ax = axes[0]\n",
    "\n",
    "multiplier = 0.5\n",
    "capsize = 0\n",
    "ax.bar(x * multiplier - 1.0 * width, infom_mean[:2], yerr=infom_std[:2], width=width, label='InFOM (Ours)', capsize=capsize, zorder=3)\n",
    "ax.bar(x * multiplier + 0.0 * width, fb_fom_mean[:2], yerr=fb_fom_std[:2], width=width, label='  FB + FOM\\n(TD flows + GPI)', capsize=capsize, zorder=3)\n",
    "ax.bar(x * multiplier + 1.0 * width, hilp_fom_mean[:2], yerr=hilp_fom_std[:2], width=width, label='HILP + FOM', capsize=capsize, zorder=3)\n",
    "# ax.yaxis.set_major_locator(MultipleLocator(200))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(100))\n",
    "eps = 0.2\n",
    "ax.set_xlim([-eps, (len(tasks[:2]) - 1) * multiplier + eps])\n",
    "ax.set_ylim([0.0, 825])\n",
    "ax.legend(fontsize=12, loc='upper left', labelspacing=0.6, columnspacing=1.8075,\n",
    "          borderpad=0.5, handlelength=1.7, ncol=1, shadow=False, fancybox=False,)\n",
    "# ax.legend(bbox_to_anchor=(-0.08, -0.12),\n",
    "#     loc=\"upper left\", labelspacing=1, columnspacing=1.8075, fancybox=False,\n",
    "#     shadow=False, fontsize=12.5, borderpad=0.35, handlelength=1.7, ncol=3)\n",
    "ax.set_xticks(x * multiplier, tasks[:2], fontsize=13)\n",
    "ax.set_yticks([0.0, 400, 800])\n",
    "ax.tick_params(axis=\"y\", labelsize=14)\n",
    "ax.set_ylabel('return', fontsize=14)\n",
    "ax.grid(zorder=0)\n",
    "\n",
    "ax = axes[1]\n",
    "\n",
    "multiplier = 0.5\n",
    "capsize = 0\n",
    "ax.bar(x * multiplier - 1.0 * width, infom_mean[2:], yerr=infom_std[2:], width=width, label='InFOM (Ours)', capsize=capsize, zorder=3)\n",
    "ax.bar(x * multiplier + 0.0 * width, fb_fom_mean[2:], yerr=fb_fom_std[2:], width=width, label='FB + FOM (TD flow + GPI)', capsize=capsize, zorder=3)\n",
    "ax.bar(x * multiplier + 1.0 * width, hilp_fom_mean[2:], yerr=hilp_fom_std[2:], width=width, label='HILP + FOM', capsize=capsize, zorder=3)\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "eps = 0.2\n",
    "ax.set_xlim([-eps, (len(tasks[2:]) - 1) * multiplier + eps])\n",
    "ax.set_ylim([0.0, 1.025])\n",
    "ax.set_xticks(x * multiplier, tasks[2:], fontsize=13)\n",
    "ax.set_yticks([0.0, 0.5, 1.0])\n",
    "ax.tick_params(axis=\"y\", labelsize=14)\n",
    "ax.set_ylabel('success rate', fontsize=14)\n",
    "ax.grid(zorder=0)\n",
    "\n",
    "fig.tight_layout(rect=(-0.02, -0.0456, 1.015, 1.04))  # rect = (left, bottom, right, top), default: (0, 0, 1, 1)\n",
    "fig.subplots_adjust(wspace=0.23)\n",
    "# filepath = \"/u/cz8792/research/ogbench/plot_scripts/figures/intention_encoding_ablation_lc.pdf\"\n",
    "filepath = \"/u/cz8792/research/ogbench/plot_scripts/figures/intention_encoding_ablation_lc.png\"\n",
    "# fig.savefig(filepath, dpi=150, bbox_inches=\"tight\")\n",
    "fig.savefig(filepath, dpi=300)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b36a99",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ogbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
